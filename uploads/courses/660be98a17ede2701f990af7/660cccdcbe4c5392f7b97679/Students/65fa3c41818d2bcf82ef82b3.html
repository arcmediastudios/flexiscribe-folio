<p><a id="_o2n6pfho1lwb"></a>4 - Fractions and Real Numbers test</p>
<table>
<tbody>
<tr>
<td>
<ol>
<li><strong>Explain the difference between a fixed-point and floating-point number.</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>Fixed-point numbers have a fixed number of digits after the decimal point, while floating-point numbers can represent a wider range of values with varying levels of precision.Top of Form</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>How is scientific notation used to represent floating point-numbers? <br>Give an example.</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<p><br>Scientific notation is used to represent floating-point numbers by expressing them as a base number multiplied by a power of 10. In scientific notation, the base number is typically a decimal number greater than or equal to 1 and less than 10, and the exponent represents the power of 10 by which the base number is multiplied.</p>
<p>For example, the number 123.45 can be represented in scientific notation as 1.2345 x 10^2, where 1.2345 is the base number and 2 is the exponent. This means that 123.45 is equal to 1.2345 multiplied by 10 raised to the power of 2, which is 100.</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>What are the sign, mantissa and exponent? <br>Show how these are used to represent a floating-point number.</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>In a floating-point representation, a number is expressed as a sign, mantissa (or significand), and exponent. The sign indicates whether the number is positive or negative, the mantissa contains the significant digits, and the exponent determines the scale of the number. Together, these components allow for the representation of a wide range of numbers with varying levels of precision.</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>What are the two different formats of floating-point numbers?</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>The two different formats of floating-point numbers are single precision (32 bits) and double precision (64 bits).</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>How many bits are allocated for the sign, mantissa and exponent for:</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>32 bit</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>1 bit is allocated for the sign,</p>
<p>8 bits for the exponent, and</p>
<p>23 bits for the mantissa.</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>64 bit</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>1 bit is allocated for the sign,</p>
<p>11 bits for the exponent, and</p>
<p>52 bits for the mantissa.</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>How can you represent positive and negative exponents using this system?</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>positive exponents are represented as simple binary numbers, while negative exponents are represented using a bias. The bias is a fixed value added to the actual exponent to ensure that it can be represented as a positive binary number.</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>Why is a leading &lsquo;one&rsquo; always added to the mantissa?</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>Adding a leading 'one' to the mantissa ensures that the mantissa is normalized, meaning that the most significant bit of the mantissa is always '1'. This allows for a more efficient representation of floating-point numbers and simplifies arithmetic operations.</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>Using the single precision standard, convert the following to decimal. <br>You must show all working out.</strong></li>
</ol>
<p><strong>E.g. </strong></p>
<p>0 10000100 01010100000000000000000</p>
<p>= + 1.010101 x 2 * (132-127)</p>
<p>= + 1.010101 x 2 * 5</p>
<p>= + 101010.1</p>
<p>= + 32 + 8 + 2 + 0.5</p>
<p>= + 42.5</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>0 10001000 00011001111000010000000</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>= +1.00011001111000010000000 x 2^(136 - 127) = +1.00011001111000010000000 x 2^9 = +100011001.11100001000000 = +256 + 128 + 64 + 16 + 8 + 4 + 2 + 1 + 0.5 = +479.5</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>0 1000010100100011100000000000000</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>ii. 0 1000010100100011100000000000000 = +1.01001000111000000000000 x 2^(138 - 127) = +1.01001000111000000000000 x 2^11 = +10100100011.1 = +2048 + 1024 + 256 + 16 + 8 + 2 + 1 + 0.5 = +3355.5</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>1 1000100011011011001000100000000</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>iii. 1 1000100011011011001000100000000 = -1.10001000110110110010001 x 2^(169 - 127) = -1.10001000110110110010001 x 2^42 = -1100.01000110110110010001 = -1024 - 64 - 8 - 4 - 0.25 - 0.125 = -1100.375</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>Using the single precision standard, convert the following to floating-point numbers. <br>You must show all working out.</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>2.75</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 2.75 to binary: 10.11</p>
<p>Normalize: 1.011 x 2^1</p>
<p>Exponent: 1 (bias is 127, so 1 + 127 = 128 = 10000000 in binary)</p>
<p>Mantissa: 01100000000000000000000 (23 bits after the leading 1)</p>
<p>Single-precision representation: 0 10000000 01100000000000000000000</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>93.875</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 93.875 to binary: 1011101.111</p>
<p>Normalize: 1.011101111 x 2^6</p>
<p>Exponent: 6 (bias is 127, so 6 + 127 = 133 = 10000101 in binary)</p>
<p>Mantissa: 01110111100000000000000 (23 bits after the leading 1)</p>
<p>Single-precision representation: 0 10000101 01110111100000000000000</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>-33.375</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert -33.375 to binary: -100001.011</p>
<p>Normalize: -1.00001011 x 2^5</p>
<p>Exponent: 5 (bias is 127, so 5 + 127 = 132 = 10000100 in binary)</p>
<p>Mantissa: 00001011000000000000000 (23 bits after the leading 1)</p>
<p>Single-precision representation: 1 10000100 00001011000000000000000</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>Using the double precision standard, convert the following to floating-point numbers. <br>You must show all working out.</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>1101.1001</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 1101.1001 to binary: 1101.000110011001100110011...</p>
<p>Normalize: 1.10100011001100110011001 x 2^3</p>
<p>Exponent: 3 (bias is 1023, so 3 + 1023 = 1026 = 10000000010 in binary)</p>
<p>Mantissa: 1010001100110011001100110011001100110011001100110011 (52 bits after the leading 1)</p>
<p>Double-precision representation: 0 10000000010 1010001100110011001100110011001100110011001100110011</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>101.111</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 101.111 to binary: 101.111</p>
<p>Normalize: 1.01111 x 2^2</p>
<p>Exponent: 2 (bias is 1023, so 2 + 1023 = 1025 = 10000000001 in binary)</p>
<p>Mantissa: 0111100000000000000000000000000000000000000000000000 (52 bits after the leading 1)</p>
<p>Double-precision representation: 0 10000000001 0111100000000000000000000000000000000000000000000000</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>1111.1111</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 1111.1111 to binary: 1111.1111</p>
<p>Normalize: 1.1111111 x 2^3</p>
<p>Exponent: 3 (bias is 1023, so 3 + 1023 = 1026 = 10000000010 in binary)</p>
<p>Mantissa: 1111111000000000000000000000000000000000000000000000 (52 bits after the leading 1)</p>
<p>Double-precision representation: 0 10000000010 1111111000000000000000000000000000000000000000000000</p>
</td>
</tr>
<tr>
<td>
<ol>
<li><strong>Using the double precision standard, convert the following to floating-point numbers. <br>You must show all working out.</strong></li>
</ol>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>12.625</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 12.625 to binary: 1100.101</p>
<p>Normalize: 1.100101 x 2^3</p>
<p>Exponent: 3 (bias is 1023, so 3 + 1023 = 1026 = 10000000010 in binary)</p>
<p>Mantissa: 1001010000000000000000000000000000000000000000000000 (52 bits after the leading 1)</p>
<p>Double-precision representation: 0 10000000010 1001010000000000000000000000000000000000000000000000</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>15.5</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 15.5 to binary: 1111.1</p>
<p>Normalize: 1.111 x 2^3</p>
<p>Exponent: 3 (bias is 1023, so 3 + 1023 = 1026 = 10000000010 in binary)</p>
<p>Mantissa: 1110000000000000000000000000000000000000000000000000 (52 bits after the leading 1)</p>
<p>Double-precision representation: 0 10000000010 1110000000000000000000000000000000000000000000000000</p>
</td>
</tr>
<tr>
<td>
<ul>
<li>
<ol>
<li><strong>32.8</strong></li>
</ol>
</li>
</ul>
</td>
</tr>
<tr>
<td>
<p>Convert 32.8 to binary: 100000.110011001100110011...</p>
<p>Normalize: 1.00000110011001100110011 x 2^5</p>
<p>Exponent: 5 (bias is 1023, so 5 + 1023 = 1028 = 10000000100 in binary)</p>
<p>Mantissa: 0000011001100110011001100110011001100110011001100110 (52 bits after the leading 1)</p>
<p>Double-precision representation: 0 10000000100 0000011001100110011001100110011001100110011001100110</p>
</td>
</tr>
</tbody>
</table>